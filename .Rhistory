select(region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
ds %>%
select(region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
{
library(ggplot2)
library(dplyr)
library(stringr)
library(lubridate)
library(gridExtra)
library(googlesheets4)
}
refresh<-function(arg){
if(arg=="pull" | arg=="all"){
googledrive::drive_find(pattern = "trans news tracker",verbose = TRUE ) -> data_sheets
dat <<- NULL
for(i in 1:dim(data_sheets)[1]){
if(i==1){googlesheets4::read_sheet(data_sheets$id[i]) ->> dat
}else{rbind(dat, googlesheets4::read_sheet(data_sheets$id[i])) -> dat }
dat -> ds ; dat ->> ds ; assign("ds",ds,envir = .GlobalEnv)}
ds %>% group_by(EntryTitle) %>% as_tibble(as.data.frame()) -> ds
pullStats()}
if(arg=="statsOnly"){pullStats()}
assign("ds",ds,envir = .GlobalEnv)
}
pullStats <- function(){
mutate(ds, theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(thetime=strptime(substr(ds$EntryPublished,nchar(ds$EntryPublished)-6,nchar(ds$EntryPublished)),format="%H:%M")) %>%
mutate(the_day=as.Date(mdy(theday))) -> ds
substring(str_extract(ds$EntryURL, pattern="https:\\/\\/?[a-z]+.[a-zA-Z0-9]+?.?[a-z]+/"), first=9) -> ds$pullURL
min_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% quantile(c(.98)))
max_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% max)
month(head(sort(ds$the_day))[1]) -> start_month
day(head(sort(ds$the_day))[1]) -> start_day
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
paste(paste(top_outlets$pullURL,sep = " | ",collapse="|"))->k
cat("\nlast 5 entries: \n\n");print(tail(ds %>% arrange(EntryPublished),n=5))
cat(paste("\n ->",dim(ds)[1]," rows, ",dim(ds)[2]," variables | avg. = ",
round(mean(as.data.frame(as.data.frame(table(ds$the_day))[2])$Freq),2), " per day\n",
"-> date range: ", min(ds$theday), "-", max(ds$theday)),"\n\n")
select(ds, region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
assign("top_outlets",top_outlets,envir = .GlobalEnv)
select(ds[which(grepl(k,ds$pullURL)),],region) %>% table() -> total
assign("ds",ds,envir = .GlobalEnv)
rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total)
}
refresh("all")
refresh<-function(arg){
if(arg=="pull" | arg=="all"){
googledrive::drive_find(pattern = "trans news tracker",verbose = TRUE ) -> data_sheets
dat <<- NULL
for(i in 1:dim(data_sheets)[1]){
if(i==1){googlesheets4::read_sheet(data_sheets$id[i]) ->> dat
}else{rbind(dat, googlesheets4::read_sheet(data_sheets$id[i])) -> dat }
dat -> ds ; dat ->> ds ; assign("ds",ds,envir = .GlobalEnv)}
ds %>% group_by(EntryTitle) %>% as_tibble(as.data.frame()) -> ds
pullStats()}
if(arg=="statsOnly"){pullStats()}
assign("ds",ds,envir = .GlobalEnv)
}
pullStats <- function(){
mutate(ds, theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(the_day=as.Date(mdy(theday))) -> ds
substring(str_extract(ds$EntryURL, pattern="https:\\/\\/?[a-z]+.[a-zA-Z0-9]+?.?[a-z]+/"), first=9) -> ds$pullURL
min_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% quantile(c(.98)))
max_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% max)
month(head(sort(ds$the_day))[1]) -> start_month
day(head(sort(ds$the_day))[1]) -> start_day
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
paste(paste(top_outlets$pullURL,sep = " | ",collapse="|"))->k
cat("\nlast 5 entries: \n\n");print(tail(ds %>% arrange(EntryPublished),n=5))
cat(paste("\n ->",dim(ds)[1]," rows, ",dim(ds)[2]," variables | avg. = ",
round(mean(as.data.frame(as.data.frame(table(ds$the_day))[2])$Freq),2), " per day\n",
"-> date range: ", min(ds$theday), "-", max(ds$theday)),"\n\n")
assign("ds",ds,envir = .GlobalEnv)
select(ds, region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
assign("top_outlets",top_outlets,envir = .GlobalEnv)
select(ds[which(grepl(k,ds$pullURL)),],region) %>% table() -> total
rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total)
}
refresh("all")
ds %>%
select(region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
refresh("all")
ds %>%
mutate(theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(the_day=as.Date(mdy(theday)))
refresh()
ds
ds %>%
mutate(theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(the_day=as.Date(mdy(theday))) -> ds
refresh()
refresh("all")
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
substring(str_extract(ds$EntryURL, pattern="https:\\/\\/?[a-z]+.[a-zA-Z0-9]+?.?[a-z]+/"), first=9) -> ds$pullURL
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
select(ds, region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
pullStats <- function(){
ds %>% mutate(theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(the_day=as.Date(mdy(theday))) -> ds
substring(str_extract(ds$EntryURL, pattern="https:\\/\\/?[a-z]+.[a-zA-Z0-9]+?.?[a-z]+/"), first=9) -> ds$pullURL
min_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% quantile(c(.98)))
max_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% max)
month(head(sort(ds$the_day))[1]) -> start_month
day(head(sort(ds$the_day))[1]) -> start_day
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
paste(paste(top_outlets$pullURL,sep = " | ",collapse="|"))->k
cat("\nlast 5 entries: \n\n");print(tail(ds %>% arrange(EntryPublished),n=5))
cat(paste("\n ->",dim(ds)[1]," rows, ",dim(ds)[2]," variables | avg. = ",
round(mean(as.data.frame(as.data.frame(table(ds$the_day))[2])$Freq),2), " per day\n",
"-> date range: ", min(ds$theday), "-", max(ds$theday)),"\n\n")
assign("ds",ds,envir = .GlobalEnv)
select(ds, region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
assign("top_outlets",top_outlets,envir = .GlobalEnv)
select(ds[which(grepl(k,ds$pullURL)),],region) %>% table() -> total
rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total)
}
refresh("all")
select(ds, region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
pullStats <- function(){
ds %>% mutate(theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(the_day=as.Date(mdy(theday))) -> ds
substring(str_extract(ds$EntryURL, pattern="https:\\/\\/?[a-z]+.[a-zA-Z0-9]+?.?[a-z]+/"), first=9) -> ds$pullURL
min_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% quantile(c(.98)))
max_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% max)
month(head(sort(ds$the_day))[1]) -> start_month
day(head(sort(ds$the_day))[1]) -> start_day
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
paste(paste(top_outlets$pullURL,sep = " | ",collapse="|"))->k
assign("ds",ds,envir = .GlobalEnv)
cat("\nlast 5 entries: \n\n");print(tail(ds %>% arrange(EntryPublished),n=5))
cat(paste("\n ->",dim(ds)[1]," rows, ",dim(ds)[2]," variables | avg. = ",
round(mean(as.data.frame(as.data.frame(table(ds$the_day))[2])$Freq),2), " per day\n",
"-> date range: ", min(ds$theday), "-", max(ds$theday)),"\n\n")
select(ds, region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
assign("top_outlets",top_outlets,envir = .GlobalEnv)
select(ds[which(grepl(k,ds$pullURL)),],region) %>% table() -> total
rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total)
}
pullStats()
k
start_day
ds %>% mutate(theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(the_day=as.Date(mdy(theday))) -> ds
substring(str_extract(ds$EntryURL, pattern="https:\\/\\/?[a-z]+.[a-zA-Z0-9]+?.?[a-z]+/"), first=9) -> ds$pullURL
min_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% quantile(c(.98)))
max_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% max)
month(head(sort(ds$the_day))[1]) -> start_month
day(head(sort(ds$the_day))[1]) -> start_day
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
assign("ds",ds,envir = .GlobalEnv)
cat("\nlast 5 entries: \n\n");print(tail(ds %>% arrange(EntryPublished),n=5))
cat(paste("\n ->",dim(ds)[1]," rows, ",dim(ds)[2]," variables | avg. = ",
round(mean(as.data.frame(as.data.frame(table(ds$the_day))[2])$Freq),2), " per day\n",
"-> date range: ", min(ds$theday), "-", max(ds$theday)),"\n\n")
select(ds, region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
assign("top_outlets",top_outlets,envir = .GlobalEnv)
select(ds[which(grepl(k,ds$pullURL)),],region) %>% table() -> total
pullStats <- function(){
ds %>% mutate(theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(the_day=as.Date(mdy(theday))) -> ds
substring(str_extract(ds$EntryURL, pattern="https:\\/\\/?[a-z]+.[a-zA-Z0-9]+?.?[a-z]+/"), first=9) -> ds$pullURL
min_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% quantile(c(.98)))
max_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% max)
month(head(sort(ds$the_day))[1]) -> start_month
day(head(sort(ds$the_day))[1]) -> start_day
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
paste(paste(top_outlets$pullURL,sep = " | ",collapse="|"))->k
assign("ds",ds,envir = .GlobalEnv)
cat("\nlast 5 entries: \n\n");print(tail(ds %>% arrange(EntryPublished),n=5))
cat(paste("\n ->",dim(ds)[1]," rows, ",dim(ds)[2]," variables | avg. = ",
round(mean(as.data.frame(as.data.frame(table(ds$the_day))[2])$Freq),2), " per day\n",
"-> date range: ", min(ds$theday), "-", max(ds$theday)),"\n\n")
select(ds, region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
assign("top_outlets",top_outlets,envir = .GlobalEnv)
select(ds[which(grepl(k,ds$pullURL)),],region) %>% table() -> total
rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total)
}
ds %>% mutate(theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(the_day=as.Date(mdy(theday))) -> ds
substring(str_extract(ds$EntryURL, pattern="https:\\/\\/?[a-z]+.[a-zA-Z0-9]+?.?[a-z]+/"), first=9) -> ds$pullURL
min_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% quantile(c(.98)))
max_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% max)
month(head(sort(ds$the_day))[1]) -> start_month
day(head(sort(ds$the_day))[1]) -> start_day
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
paste(paste(top_outlets$pullURL,sep = " | ",collapse="|"))->k
assign("ds",ds,envir = .GlobalEnv)
cat("\nlast 5 entries: \n\n");print(tail(ds %>% arrange(EntryPublished),n=5))
cat(paste("\n ->",dim(ds)[1]," rows, ",dim(ds)[2]," variables | avg. = ",
round(mean(as.data.frame(as.data.frame(table(ds$the_day))[2])$Freq),2), " per day\n",
"-> date range: ", min(ds$theday), "-", max(ds$theday)),"\n\n")
select(ds, region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
assign("top_outlets",top_outlets,envir = .GlobalEnv)
select(ds[which(grepl(k,ds$pullURL)),],region) %>% table() -> total
rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total)
pullStats <- function(){
ds %>% mutate(theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(the_day=as.Date(mdy(theday))) -> ds
substring(str_extract(ds$EntryURL, pattern="https:\\/\\/?[a-z]+.[a-zA-Z0-9]+?.?[a-z]+/"), first=9) -> ds$pullURL
min_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% quantile(c(.98)))
max_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% max)
month(head(sort(ds$the_day))[1]) -> start_month
day(head(sort(ds$the_day))[1]) -> start_day
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
paste(paste(top_outlets$pullURL,sep = " | ",collapse="|"))->k
cat("\nlast 5 entries: \n\n");print(tail(ds %>% arrange(EntryPublished),n=5))
cat(paste("\n ->",dim(ds)[1]," rows, ",dim(ds)[2]," variables | avg. = ",
round(mean(as.data.frame(as.data.frame(table(ds$the_day))[2])$Freq),2), " per day\n",
"-> date range: ", min(ds$theday), "-", max(ds$theday)),"\n\n")
select(ds, region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
assign("top_outlets",top_outlets,envir = .GlobalEnv)
select(ds[which(grepl(k,ds$pullURL)),],region) %>% table() -> total
rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total)
assign("ds",ds,envir = .GlobalEnv)
}
pullStats()
refresh("all")
pullStats()
top_outlets
rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total)
rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total)
pullStats <- function(){
ds %>% mutate(theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(the_day=as.Date(mdy(theday))) -> ds
substring(str_extract(ds$EntryURL, pattern="https:\\/\\/?[a-z]+.[a-zA-Z0-9]+?.?[a-z]+/"), first=9) -> ds$pullURL
min_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% quantile(c(.98)))
max_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% max)
month(head(sort(ds$the_day))[1]) -> start_month
day(head(sort(ds$the_day))[1]) -> start_day
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
paste(paste(top_outlets$pullURL,sep = " | ",collapse="|"))->k
cat("\nlast 5 entries: \n\n");print(tail(ds %>% arrange(EntryPublished),n=5))
cat(paste("\n ->",dim(ds)[1]," rows, ",dim(ds)[2]," variables | avg. = ",
round(mean(as.data.frame(as.data.frame(table(ds$the_day))[2])$Freq),2), " per day\n",
"-> date range: ", min(ds$theday), "-", max(ds$theday)),"\n\n")
select(ds, region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
assign("top_outlets",top_outlets,envir = .GlobalEnv)
select(ds[which(grepl(k,ds$pullURL)),],region) %>% table() -> total
(rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total))
assign("ds",ds,envir = .GlobalEnv)
}
pullStats()
(rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total))
cat(rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total))
rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total)
closeAllConnections()
pullStats()
top_outlets
total
rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total)
pullStats <- function(){
ds %>% mutate(theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(the_day=as.Date(mdy(theday))) -> ds
substring(str_extract(ds$EntryURL, pattern="https:\\/\\/?[a-z]+.[a-zA-Z0-9]+?.?[a-z]+/"), first=9) -> ds$pullURL
min_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% quantile(c(.98)))
max_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% max)
month(head(sort(ds$the_day))[1]) -> start_month
day(head(sort(ds$the_day))[1]) -> start_day
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
paste(paste(top_outlets$pullURL,sep = " | ",collapse="|"))->k
cat("\nlast 5 entries: \n\n");print(tail(ds %>% arrange(EntryPublished),n=5))
cat(paste("\n ->",dim(ds)[1]," rows, ",dim(ds)[2]," variables | avg. = ",
round(mean(as.data.frame(as.data.frame(table(ds$the_day))[2])$Freq),2), " per day\n",
"-> date range: ", min(ds$theday), "-", max(ds$theday)),"\n\n")
select(ds, region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
assign("top_outlets",top_outlets,envir = .GlobalEnv)
select(ds[which(grepl(k,ds$pullURL)),],region) %>% table() -> total
return(rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total))
assign("ds",ds,envir = .GlobalEnv)
}
pullStats()
{
library(ggplot2)
library(dplyr)
library(stringr)
library(lubridate)
library(gridExtra)
library(googlesheets4)
}
refresh<-function(arg){
if(arg=="pull" | arg=="all"){
googledrive::drive_find(pattern = "trans news tracker",verbose = TRUE ) -> data_sheets
dat <<- NULL
for(i in 1:dim(data_sheets)[1]){
if(i==1){googlesheets4::read_sheet(data_sheets$id[i]) ->> dat
}else{rbind(dat, googlesheets4::read_sheet(data_sheets$id[i])) -> dat }
dat -> ds ; dat ->> ds ; assign("ds",ds,envir = .GlobalEnv)}
ds %>% group_by(EntryTitle) %>% as_tibble(as.data.frame()) -> ds
pullStats()}
if(arg=="statsOnly"){pullStats()}
assign("ds",ds,envir = .GlobalEnv)
}
pullStats <- function(){
ds %>% mutate(theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(the_day=as.Date(mdy(theday))) -> ds
substring(str_extract(ds$EntryURL, pattern="https:\\/\\/?[a-z]+.[a-zA-Z0-9]+?.?[a-z]+/"), first=9) -> ds$pullURL
min_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% quantile(c(.98)))
max_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% max)
month(head(sort(ds$the_day))[1]) -> start_month
day(head(sort(ds$the_day))[1]) -> start_day
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
paste(paste(top_outlets$pullURL,sep = " | ",collapse="|"))->k
cat("\nlast 5 entries: \n\n");print(tail(ds %>% arrange(EntryPublished),n=5))
cat(paste("\n ->",dim(ds)[1]," rows, ",dim(ds)[2]," variables | avg. = ",
round(mean(as.data.frame(as.data.frame(table(ds$the_day))[2])$Freq),2), " per day\n",
"-> date range: ", min(ds$theday), "-", max(ds$theday)),"\n\n")
select(ds, region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
assign("top_outlets",top_outlets,envir = .GlobalEnv)
select(ds[which(grepl(k,ds$pullURL)),],region) %>% table() -> total
return(rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total))
assign("ds",ds,envir = .GlobalEnv)
}
refresh("all")
select(ds, region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
ds %>% mutate(theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(the_day=as.Date(mdy(theday))) -> ds
substring(str_extract(ds$EntryURL, pattern="https:\\/\\/?[a-z]+.[a-zA-Z0-9]+?.?[a-z]+/"), first=9) -> ds$pullURL
min_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% quantile(c(.98)))
max_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% max)
month(head(sort(ds$the_day))[1]) -> start_month
day(head(sort(ds$the_day))[1]) -> start_day
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
paste(paste(top_outlets$pullURL,sep = " | ",collapse="|"))->k
ds %>% mutate(theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(the_day=as.Date(mdy(theday))) -> ds
substring(str_extract(ds$EntryURL, pattern="https:\\/\\/?[a-z]+.[a-zA-Z0-9]+?.?[a-z]+/"), first=9) -> ds$pullURL
min_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% quantile(c(.98)))
max_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% max)
month(head(sort(ds$the_day))[1]) -> start_month
day(head(sort(ds$the_day))[1]) -> start_day
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
paste(paste(top_outlets$pullURL,sep = " | ",collapse="|"))->k
pullStats <- function(){
ds %>% mutate(theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(the_day=as.Date(mdy(theday))) -> ds
substring(str_extract(ds$EntryURL, pattern="https:\\/\\/?[a-z]+.[a-zA-Z0-9]+?.?[a-z]+/"), first=9) -> ds$pullURL
min_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% quantile(c(.98)))
max_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% max)
month(head(sort(ds$the_day))[1]) -> start_month
day(head(sort(ds$the_day))[1]) -> start_day
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
cat("\nlast 5 entries: \n\n");print(tail(ds %>% arrange(EntryPublished),n=5))
cat(paste("\n ->",dim(ds)[1]," rows, ",dim(ds)[2]," variables | avg. = ",
round(mean(as.data.frame(as.data.frame(table(ds$the_day))[2])$Freq),2), " per day\n",
"-> date range: ", min(ds$theday), "-", max(ds$theday)),"\n\n")
select(ds, region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
assign("top_outlets",top_outlets,envir = .GlobalEnv)
select(ds[which(grepl(k,ds$pullURL)),],region) %>% table() -> total
return(rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total))
assign("ds",ds,envir = .GlobalEnv)
}
pullStats()
paste(paste(top_outlets$pullURL,sep = " | ",collapse="|"))->k
return(rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total))
select(ds[which(grepl(k,ds$pullURL)),],region) %>% table() -> total
return(rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total))
ds %>% mutate(theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(the_day=as.Date(mdy(theday))) -> ds
substring(str_extract(ds$EntryURL, pattern="https:\\/\\/?[a-z]+.[a-zA-Z0-9]+?.?[a-z]+/"), first=9) -> ds$pullURL
min_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% quantile(c(.98)))
max_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% max)
month(head(sort(ds$the_day))[1]) -> start_month
day(head(sort(ds$the_day))[1]) -> start_day
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
paste(paste(top_outlets$pullURL,sep = " | ",collapse="|"))->k
cat("\nlast 5 entries: \n\n");print(tail(ds %>% arrange(EntryPublished),n=5))
cat(paste("\n ->",dim(ds)[1]," rows, ",dim(ds)[2]," variables | avg. = ",
round(mean(as.data.frame(as.data.frame(table(ds$the_day))[2])$Freq),2), " per day\n",
"-> date range: ", min(ds$theday), "-", max(ds$theday)),"\n\n")
select(ds, region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
assign("top_outlets",top_outlets,envir = .GlobalEnv)
select(ds[which(grepl(k,ds$pullURL)),],region) %>% table() -> total
return(rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total))
return(rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total))
ds %>% group_by(the_day,region,keyword) %>% mutate(ct=n()) %>% ggplot()+
geom_line(aes(x=the_day,y=ct,color=region, colour="daily"))+
geom_point(aes(x=the_day,y=ct,color=region, colour="daily"))+
labs(title = "Articles about trans people in US + UK news media",
subtitle = "https://tech.lgbt/@jessdkant",
caption=paste("updated",Sys.time()))+
xlab(element_blank())+
ylab("number of articles")+
theme_bw()+
theme(legend.position = "bottom")+
facet_grid(keyword~region) -> kw
kw
top_outlets %>% ggplot()+
theme_minimal()+
scale_fill_discrete(element_blank())+
geom_bar(aes(x=count,fill=pullURL),position = "dodge")+
theme(legend.position = "bottom",
axis.text.y = element_blank())+
labs(y=element_blank(),x="# articles per outlet",
title = paste("\ntop news sources, 98th percentile (",round(min_arts),"+ max = ", max_arts, ") since: ",
start_month,"/",start_day,": \n", sep="")) -> urlPlot
ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region,keyword) %>%
ggplot()+
theme_bw()+
scale_fill_discrete(element_blank())+
geom_bar(aes(x=pullURL,fill=pullURL),position = "dodge")+
theme(legend.position = "none",
axis.text.x = element_blank(),
axis.ticks.x = element_blank())+
labs(y=element_blank(),x=element_blank(),title = "Top drivers of conversation by region + keyword")+
facet_grid(keyword~region) -> top_plot
gridExtra::grid.arrange(kw,bottom,urlPlot,heights=c(2,2,1.25))
ds %>%
ggplot()+
geom_bar(aes(x=the_day, fill=topic), position="fill")+
facet_grid(keyword~region)+
theme_bw()+
theme(legend.position = "bottom")+
scale_fill_discrete(name="keyword")+
labs(y="proportion of articles",x=element_blank()) -> bottom
refresh<-function(arg){
if(arg=="pull" | arg=="all"){
googledrive::drive_find(pattern = "trans news tracker",verbose = TRUE ) -> data_sheets
dat <<- NULL
for(i in 1:dim(data_sheets)[1]){
if(i==1){googlesheets4::read_sheet(data_sheets$id[i]) ->> dat
}else{rbind(dat, googlesheets4::read_sheet(data_sheets$id[i])) -> dat }
dat -> ds ; dat ->> ds ; assign("ds",ds,envir = .GlobalEnv)}
ds %>% group_by(EntryTitle) %>% as_tibble(as.data.frame()) -> ds
pullStats()}
if(arg=="statsOnly"){pullStats()}
assign("ds",ds,envir = .GlobalEnv)
}
pullStats <- function(){
ds %>% mutate(theday=str_extract(EntryPublished,pattern = "[a-zA-Z]+\\s[0-9]+\\,\\s20[0-9]+")) %>%
mutate(the_day=as.Date(mdy(theday))) -> ds
substring(str_extract(ds$EntryURL, pattern="https:\\/\\/?[a-z]+.[a-zA-Z0-9]+?.?[a-z]+/"), first=9) -> ds$pullURL
min_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% quantile(c(.98)))
max_arts <- as.numeric(summarize(group_by(ds %>% filter(!is.na(pullURL)), pullURL),ct=n())$ct %>% max)
month(head(sort(ds$the_day))[1]) -> start_month
day(head(sort(ds$the_day))[1]) -> start_day
gsub(pattern="/",replace="",ds$pullURL)->ds$pullURL
paste(paste(top_outlets$pullURL,sep = " | ",collapse="|"))->k
cat("\nlast 5 entries: \n\n");print(tail(ds %>% arrange(EntryPublished),n=5))
cat(paste("\n ->",dim(ds)[1]," rows, ",dim(ds)[2]," variables | avg. = ",
round(mean(as.data.frame(as.data.frame(table(ds$the_day))[2])$Freq),2), " per day\n",
"-> date range: ", min(ds$theday), "-", max(ds$theday)),"\n\n")
select(ds, region, the_day, pullURL) %>%
filter(!is.na(pullURL) & pullURL != "www.youtube.com/") %>%
group_by(pullURL,.drop=FALSE) %>%
summarize(count=n()) %>% filter(count>min_arts) -> top_outlets
assign("top_outlets",top_outlets,envir = .GlobalEnv)
select(ds[which(grepl(k,ds$pullURL)),],region) %>% table() -> total
return(rbind(ds[which(grepl(k,ds$pullURL)),] %>% select(pullURL,region) %>% table(),total))
assign("ds",ds,envir = .GlobalEnv)
}
refresh("all")
pullStats()
